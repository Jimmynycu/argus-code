Namespace(pretrained_model_name_or_path='stabilityai/stable-video-diffusion-img2vid', revision=None, train_base_folder=['/share/ma/scratch/rundong/360-clips'], train_clip_file='/share/ma/scratch/rundong/360-clips/split-files/orifps-motion75-0.02_alltext/train.txt', wanted_name_in_dataset=None, val_base_folder=['/share/ma/scratch/rundong/360-clips'], val_clip_file='/share/ma/scratch/rundong/360-clips/split-files/orifps-motion75-0.02_alltext/test.txt', num_frames=25, width=768, height=384, frame_rate=5, min_frame_rate=None, max_frame_rate=None, fixed_rpy=False, center_yaw=True, fov_x_min=30.0, fov_x_max=120.0, fov_y_min=30.0, fov_y_max=120.0, fixed_start_frame=False, train_dataset_size=None, rotation_during_inference=False, inference_final_rotation=0.0, blend_decoding_ratio=4, extended_decoding=True, rotation=True, num_validation_each_step=1, validation_steps=250, output_dir='experiments/stage1', equirectangular_weighing=True, equirectangular_weighing_alpha=0.25, noise_mean=[0.0, 0.5, 1.0], noise_std=[1.0, 1.0, 1.0], noise_schedule=[5000, 10000, 15000], noise_conditioning=False, noise_conditioning_strength=0.25, full_perspective_input_prob=1, num_known_frames=0, spatial_only=False, temporal_only=False, experiment_name='stage1', seed=None, per_gpu_batch_size=1, max_train_steps=25000, gradient_accumulation_steps=1, gradient_checkpointing=True, learning_rate=1e-05, scale_lr=False, lr_scheduler='constant', lr_warmup_steps=0, conditioning_dropout_prob=0.2, allow_tf32=False, num_workers=8, adam_beta1=0.9, adam_beta2=0.999, adam_weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, push_to_hub=False, hub_token=None, hub_model_id=None, logging_dir='logs', mixed_precision='fp16', report_to='tensorboard', local_rank=0, checkpointing_steps=500, latest_checkpointing_steps=250, checkpoints_total_limit=4, resume_from_checkpoint=None, pretrain_unet=None)
Namespace(pretrained_model_name_or_path='stabilityai/stable-video-diffusion-img2vid', revision=None, train_base_folder=['/share/ma/scratch/rundong/360-clips'], train_clip_file='/share/ma/scratch/rundong/360-clips/split-files/orifps-motion75-0.02_alltext/train.txt', wanted_name_in_dataset=None, val_base_folder=['/share/ma/scratch/rundong/360-clips'], val_clip_file='/share/ma/scratch/rundong/360-clips/split-files/orifps-motion75-0.02_alltext/test.txt', num_frames=25, width=768, height=384, frame_rate=5, min_frame_rate=None, max_frame_rate=None, fixed_rpy=False, center_yaw=True, fov_x_min=30.0, fov_x_max=120.0, fov_y_min=30.0, fov_y_max=120.0, fixed_start_frame=False, train_dataset_size=None, rotation_during_inference=False, inference_final_rotation=0.0, blend_decoding_ratio=4, extended_decoding=True, rotation=True, num_validation_each_step=1, validation_steps=250, output_dir='experiments/stage1', equirectangular_weighing=True, equirectangular_weighing_alpha=0.25, noise_mean=[0.0, 0.5, 1.0], noise_std=[1.0, 1.0, 1.0], noise_schedule=[5000, 10000, 15000], noise_conditioning=False, noise_conditioning_strength=0.25, full_perspective_input_prob=1, num_known_frames=0, spatial_only=False, temporal_only=False, experiment_name='stage1', seed=None, per_gpu_batch_size=1, max_train_steps=25000, gradient_accumulation_steps=1, gradient_checkpointing=True, learning_rate=1e-05, scale_lr=False, lr_scheduler='constant', lr_warmup_steps=0, conditioning_dropout_prob=0.2, allow_tf32=False, num_workers=8, adam_beta1=0.9, adam_beta2=0.999, adam_weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, push_to_hub=False, hub_token=None, hub_model_id=None, logging_dir='logs', mixed_precision='fp16', report_to='tensorboard', local_rank=0, checkpointing_steps=500, latest_checkpointing_steps=250, checkpoints_total_limit=4, resume_from_checkpoint=None, pretrain_unet=None)
Namespace(pretrained_model_name_or_path='stabilityai/stable-video-diffusion-img2vid', revision=None, train_base_folder=['/share/ma/scratch/rundong/360-clips'], train_clip_file='/home/rl897/data_filtering/split-files/orifps-10seconds-motionp75_0.1-woText_high_quality/train.txt', wanted_name_in_dataset=None, val_base_folder=['/share/ma/scratch/rundong/360-clips'], val_clip_file='/home/rl897/data_filtering/split-files/orifps-10seconds-motionp75_0.1-woText_high_quality/test.txt', num_frames=25, width=768, height=384, frame_rate=5, min_frame_rate=None, max_frame_rate=None, fixed_rpy=False, center_yaw=True, fov_x_min=30.0, fov_x_max=120.0, fov_y_min=30.0, fov_y_max=120.0, fixed_start_frame=False, train_dataset_size=None, rotation_during_inference=False, inference_final_rotation=0.0, blend_decoding_ratio=4, extended_decoding=True, rotation=True, num_validation_each_step=1, validation_steps=250, output_dir='experiments/stage1', equirectangular_weighing=True, equirectangular_weighing_alpha=0.25, noise_mean=[0.0, 0.5, 1.0], noise_std=[1.0, 1.0, 1.0], noise_schedule=[5000, 10000, 15000], noise_conditioning=False, noise_conditioning_strength=0.25, full_perspective_input_prob=1, num_known_frames=0, spatial_only=False, temporal_only=False, experiment_name='stage1', seed=None, per_gpu_batch_size=1, max_train_steps=25000, gradient_accumulation_steps=1, gradient_checkpointing=True, learning_rate=1e-05, scale_lr=False, lr_scheduler='constant', lr_warmup_steps=0, conditioning_dropout_prob=0.2, allow_tf32=False, num_workers=8, adam_beta1=0.9, adam_beta2=0.999, adam_weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, push_to_hub=False, hub_token=None, hub_model_id=None, logging_dir='logs', mixed_precision='fp16', report_to='tensorboard', local_rank=0, checkpointing_steps=500, latest_checkpointing_steps=250, checkpoints_total_limit=4, resume_from_checkpoint=None, pretrain_unet=None)
***** Running training *****
  Num examples = 29526
  Instantaneous batch size per device = 1
  Total train batch size (w. parallel, distributed & accumulation) = 4
  Gradient Accumulation steps = 1
  Total optimization steps = 25000
Step 1 - Loss: 0.23661448061466217 - Time: 18.613910675048828
Validation step at step %d 1
