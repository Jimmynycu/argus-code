{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Showcase: 2D to 360¬∞ Video Generation (Final, Corrected Version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a comprehensive and robust showcase for the 'Beyond the Frame' project. It has been redesigned to be as reliable as possible, with a self-correcting setup process.\n\n### **Instructions**\n\n1.  **GPU Runtime:** Ensure your runtime is set to use a GPU (`Runtime` > `Change runtime type` > `T4 GPU`).\n2.  **Run Cells in Order:** Execute each cell from top to bottom. There are only two main steps required before you can run the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Install Conda & Restart Kernel**\n\n‚ö†Ô∏è **CRITICAL STEP** ‚ö†Ô∏è\n\nRunning the cell below will install `conda` and **automatically restart the Colab kernel.** This is expected and necessary.\n\n**After the kernel restarts, you must continue running the cells from Step 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### **Step 2: Full Setup & Verification (Run This After Kernel Restart)**\n\n**IMPORTANT:** Run this single cell *after* the kernel has restarted from Step 1. \n\nThis cell is **idempotent**, meaning it can be run multiple times without causing errors. It will automatically clean up any previous runs before starting. It will:\n1.  Delete any old project files.\n2.  Clone the project repository.\n3.  Install all dependencies in the correct order.\n4.  Download all required AI models from their correct sources.\n5.  Verify that all files are in the correct place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# --- Start of Setup ---\n",
    "print('Starting setup... This may take several minutes.')\n",
    "\n",
    "# Ensure we are in the root directory and clean up previous runs\n",
    "if os.path.basename(os.getcwd()) == 'argus-code':\n",
    "    os.chdir('..')\n",
    "print('Cleaning up previous runs...')\n",
    "!rm -rf argus-code\n",
    "print('‚úÖ Cleanup complete.')\n",
    "\n",
    "def run_and_verify(command, check_path=None, failure_message=''):\n",
    "    print(f'--- Running: {failure_message} ---')\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f'‚ùå FATAL: {failure_message} failed.')\n",
    "        print(f'--- STDOUT ---\\n{result.stdout}')\n",
    "        print(f'--- STDERR ---\\n{result.stderr}')\n",
    "        sys.exit(1)\n",
    "    if check_path and not os.path.exists(check_path):\n",
    "        print(f'‚ùå FATAL: Verification failed. Expected path does not exist: {check_path}')\n",
    "        sys.exit(1)\n",
    "    print(f'‚úÖ {failure_message} successful.')\n",
    "\n",
    "# --- Step 2.1: Clone Repository ---\n",
    "run_and_verify('git clone --recurse-submodules https://github.com/Red-Fairy/argus-code', \n",
    "                 check_path='argus-code', \n",
    "                 failure_message='Cloning repository')\n",
    "os.chdir('argus-code')\n",
    "\n",
    "# --- Step 2.2: Install Dependencies ---\n",
    "run_and_verify('pip install gdown --upgrade', failure_message='Upgrading gdown') # Ensure gdown is recent enough for --folder\n",
    "run_and_verify('conda install -y -c pytorch -c nvidia faiss-gpu=1.8.0 cython', \n",
    "                 failure_message='Conda installation')\n",
    "run_and_verify('pip install -q -r requirements.txt', \n",
    "                 failure_message='Pip requirements installation')\n",
    "run_and_verify('pip install -q yt-dlp', \n",
    "                 failure_message='Pip yt-dlp installation')\n",
    "\n",
    "# --- Step 2.3: Compile ASMK ---\n",
    "run_and_verify('git clone https://github.com/jenicek/asmk', \n",
    "                 check_path='asmk', \n",
    "                 failure_message='Cloning ASMK')\n",
    "os.chdir('asmk/cython/')\n",
    "run_and_verify('cythonize *.pyx', \n",
    "                 failure_message='Cythonizing ASMK')\n",
    "os.chdir('..')\n",
    "run_and_verify('pip install .', \n",
    "                 failure_message='Installing ASMK')\n",
    "os.chdir('..')\n",
    "\n",
    "# --- Step 2.4: Download Models ---\n",
    "os.makedirs('checkpoints/pretrained-weights/unet', exist_ok=True)\n",
    "run_and_verify('gdown --id 1PFRmbD9rLp6HZWobIMMfiasftmyT4xMW -O checkpoints/pretrained-weights/config.json', \n",
    "               check_path='checkpoints/pretrained-weights/config.json', \n",
    "               failure_message='Downloading config.json')\n",
    "\n",
    "run_and_verify('gdown --id 1Yq0wEX243L7O2S21zywz2UP-0B53QZz7 -O checkpoints/pretrained-weights/unet/diffusion_pytorch_model.safetensors', \n",
    "               check_path='checkpoints/pretrained-weights/unet/diffusion_pytorch_model.safetensors', \n",
    "               failure_message='Downloading UNet Safetensors')\n",
    "\n",
    "os.makedirs('mega-sam/Depth-Anything/checkpoints', exist_ok=True)\n",
    "run_and_verify('wget -q https://huggingface.co/spaces/LiheYoung/Depth-Anything/resolve/main/checkpoints/depth_anything_vitl14.pth -O mega-sam/Depth-Anything/checkpoints/depth_anything_vitl14.pth', \n",
    "                 check_path='mega-sam/Depth-Anything/checkpoints/depth_anything_vitl14.pth', \n",
    "                 failure_message='Downloading DepthAnything model')\n",
    "\n",
    "os.makedirs('mega-sam/cvd_opt', exist_ok=True)\n",
    "run_and_verify('wget -q https://huggingface.co/ddrfan/RAFT/resolve/bfb9a87633743408b9c13c20b9ed43dbe5b83617/raft-things.pth -O mega-sam/cvd_opt/raft-things.pth', \n",
    "                 check_path='mega-sam/cvd_opt/raft-things.pth', \n",
    "                 failure_message='Downloading RAFT model')\n",
    "\n",
    "# --- Step 2.5: Verify Final Files ---\n",
    "files_to_check = [\n",
    "    'checkpoints/pretrained-weights/unet/diffusion_pytorch_model.safetensors',\n",
    "    'checkpoints/pretrained-weights/config.json',\n",
    "    'mega-sam/Depth-Anything/checkpoints/depth_anything_vitl14.pth',\n",
    "    'mega-sam/cvd_opt/raft-things.pth'\n",
    "]\n",
    "for f in files_to_check:\n",
    "    run_and_verify('', check_path=f, failure_message=f'Verifying final file: {f}')\n",
    "    \n",
    "print('\\n--- ‚úÖ‚úÖ‚úÖ SETUP COMPLETE AND FULLY VERIFIED ‚úÖ‚úÖ‚úÖ ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Automated Processing from a URL**\n\nRun the two cells below to automatically download a video from a URL and process it using the command-line script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- You can change this URL to any video you want to process ---\n",
    "video_url = 'https://www.youtube.com/watch?v=YE7VzlLtp-4' # Big Buck Bunny (placeholder)\n",
    "\n",
    "!mkdir -p input_videos\n",
    "!yt-dlp -o 'input_videos/video.mp4' -f 'best[height<=720]' {video_url}\n",
    "\n",
    "video_path = 'input_videos/video.mp4'\n",
    "if os.path.exists(video_path):\n",
    "    print(f'‚úÖ Video downloaded successfully to: {video_path}')\n",
    "else:\n",
    "    print(f'‚ùå FAILED to download video. The URL may be invalid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(video_path):\n",
    "    print('Starting automated processing...')\n",
    "    unet_path = './checkpoints/pretrained-weights'\n",
    "    save_folder = './outputs'\n",
    "    \n",
    "    !python inference.py \\\n",
    "        --unet_path {unet_path} \\\n",
    "        --video_path {video_path} \\\n",
    "        --val_save_folder {save_folder} \\\n",
    "        --guidance_scale 3 \\\n",
    "        --num_inference_steps 25\n",
    "    \n",
    "    print(f'\\n--- Processing Complete! ---\\n')\n",
    "    print(f'Check the `{save_folder}` directory for your generated 360¬∞ video.')\n",
    "else:\n",
    "    print('Skipping processing because video download failed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}