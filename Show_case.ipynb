{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Showcase: 2D to 360Â° Video Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a comprehensive showcase for the 'Beyond the Frame' project. It will guide you through setting up the environment and then offer two distinct ways to demo the technology:\n\n*   **Option 1: Interactive Demo** - Launch a web interface to upload your own videos.\n*   **Option 2: Automated Processing** - Automatically download a video from a URL and process it.\n\n**Instructions:**\n1. Make sure your runtime is set to use a GPU (`Runtime` > `Change runtime type` > `T4 GPU`).\n2. Run the 'Common Setup' cells first.\n3. Choose **one** of the two demo options and run its corresponding cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Common Setup (Run These Cells First)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cloning repository...')\n",
    "!git clone --recurse-submodules https://github.com/Red-Fairy/argus-code\n",
    "%cd argus-code\n",
    "\n",
    "print('Installing dependencies...')\n",
    "# Install faiss-gpu first to prevent errors, then install other requirements.\n",
    "!pip install -q faiss-gpu\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q yt-dlp gdown\n",
    "\n",
    "print('Cloning and installing asmk...')\n",
    "!git clone https://github.com/jenicek/asmk\n",
    "%cd asmk/cython/\n",
    "!cythonize *.pyx\n",
    "%cd ..\n",
    "!pip install .\n",
    "%cd ..\n",
    "print('All dependencies installed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Downloading pre-trained models...')\n",
    "!mkdir -p checkpoints\n",
    "!gdown --id 1mZpViQY2yvwav-CcxdsQouYu8t52b25G -O checkpoints/pretrained-weights.zip\n",
    "!unzip -q checkpoints/pretrained-weights.zip -d checkpoints/\n",
    "\n",
    "!mkdir -p mega-sam/Depth-Anything/checkpoints\n",
    "!wget -q https://huggingface.co/spaces/LiheYoung/Depth-Anything/resolve/main/checkpoints/depth_anything_vitl14.pth -O mega-sam/Depth-Anything/checkpoints/depth_anything_vitl14.pth\n",
    "\n",
    "!mkdir -p mega-sam/cvd_opt\n",
    "!gdown --id 1sWDsfuZ3Up38EUQt7-JDTT1HcGHuJgvT -O mega-sam/cvd_opt/raft-things.pth\n",
    "print('Models downloaded successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Choose Your Demo\n\n**Important:** Only run the cells for the option you want to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Interactive Demo (Gradio Web UI)\n\nRun the cell below to launch a Gradio web interface. A public URL will be generated. Click it to open the demo in a new tab, where you can upload your own video for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python gradio_demo.py --share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Automated Processing from a URL\n\nRun the two cells below to automatically download a video from a URL and process it using the command-line script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- You can change this URL to any video you want to process ---\n",
    "video_url = 'https://www.youtube.com/watch?v=YE7VzlLtp-4' # Big Buck Bunny (placeholder)\n",
    "\n",
    "!mkdir -p input_videos\n",
    "!yt-dlp -o 'input_videos/video.mp4' -f 'best[height<=720]' {video_url}\n",
    "\n",
    "video_path = 'input_videos/video.mp4'\n",
    "print(f'Video downloaded to: {video_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting automated processing...')\n",
    "unet_path = './checkpoints/pretrained-weights'\n",
    "save_folder = './outputs'\n",
    "\n",
    "!python inference.py \\\n",
    "    --unet_path {unet_path} \\\n",
    "    --video_path {video_path} \\\n",
    "    --val_save_folder {save_folder} \\\n",
    "    --guidance_scale 3 \\\n",
    "    --num_inference_steps 25\n",
    "\n",
    "print(f'\\n--- Processing Complete! ---\\n')\n",
    "print(f'Check the `{save_folder}` directory for your generated 360Â° video.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}